{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data after preprocessing\n",
    "data = pd.read_csv('../../data/data/data_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_model(model,\n",
    "                    degree:int|tuple[int, int], \n",
    "                    X:pd.DataFrame,\n",
    "                    y:list,\n",
    "                    train_model = True,\n",
    "                    predict_model = False\n",
    "                    ) -> Union[None,np.array]:\n",
    "    \"\"\"Create polynomial model with given degree on the features and target.\n",
    "    Using PolynomialFeatures() to generate polynomial included interaction features only.\n",
    "    it can fit the model on the new features from PolynomialFeatures() generated.\n",
    "    and predict target data by the new features from PolynomialFeatures() generated.\n",
    "\n",
    "    Args:\n",
    "        model (ScikitModel): model\n",
    "        degree ([int or tuple(int, int)]): could be single number assign to maximal degree, \n",
    "                                            or tuple of numbers assign to (min_degree, max_degree).\n",
    "        X (pd.DataFrame): samples of features dataframe.\n",
    "        y (list, optional): samples of target column.\n",
    "        train_model (bool, optional): train model on new features from polynomial features model. Defaults to True.\n",
    "        predict_model (bool, optional): predict target data on new features from polynomial features model. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        (None or np.array): nothing when train model and an array contains predicted values when predict model.\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree, interaction_only=True)\n",
    "    poly.fit(X)\n",
    "    new_features = poly.transform(X)\n",
    "    \n",
    "    if train_model:\n",
    "        model.fit(new_features, y)\n",
    "    \n",
    "    if predict_model:\n",
    "        predict_data = model.predict(new_features) \n",
    "        return predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models:dict,\n",
    "                X_train:pd.DataFrame, \n",
    "                y_train:list) -> dict:\n",
    "    \"\"\"Training all models in the dictionary on the features and target variable.\n",
    "    Keeping in view the degree number, if any.\n",
    "\n",
    "    Args:\n",
    "        models (dict): Contains model name (key), model and degree number (optional).\n",
    "        X_train (pd.DataFrame): features dataframe.\n",
    "        y_train (list): target column.\n",
    "\n",
    "    Returns:\n",
    "        (dict): New dictionary contains models trained.\n",
    "    \"\"\"\n",
    "    for model_id in models:\n",
    "        degree = models[model_id].get('degree') if models[model_id].get('degree') else None\n",
    "        \n",
    "        polynomial_model(model=models[model_id]['model'],\n",
    "                            degree=degree,\n",
    "                            X=X_train,\n",
    "                            y=y_train) if degree else models[model_id]['model'].fit(X_train, y_train)\n",
    "\n",
    "        print('Trained -> ', models[model_id])\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_models(models:dict,\n",
    "                      X:pd.DataFrame, \n",
    "                      y:list,\n",
    "                      train:bool = False) -> dict:\n",
    "    \"\"\"Evaluation all models in the given dictionary by score R.\n",
    "    Keeping in view the degree number, if any.\n",
    "\n",
    "    Args:\n",
    "        models (dict): Contains model name (key), model and degree number (optional).\n",
    "        X (pd.DataFrame): Features dataframe.\n",
    "        y (list): Target column.\n",
    "        train (bool, optional): Whether to save the score in train_score or test_score. \n",
    "                                if set to True, the score will saved in train_score value dictionary. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Same given dictionary in addition to the score value for each model.\n",
    "    \"\"\"\n",
    "    for model_id in models:\n",
    "        degree = models[model_id].get('degree') if models[model_id].get('degree') else None\n",
    "        \n",
    "        y_predict = polynomial_model(model = models[model_id]['model'],\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    degree=degree,\n",
    "                                    train_model=False,\n",
    "                                    predict_model=True\n",
    "                                    ) if degree else models[model_id]['model'].predict(X)\n",
    "\n",
    "        score = r2_score(y_predict, y)\n",
    "        \n",
    "        if train:\n",
    "            models[model_id][\"Train_Score\"] = score\n",
    "        else:\n",
    "            models[model_id][\"Test_Score\"] = score\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select All features exclude target feature\n",
    "X = data[data.drop('price', axis=1).columns]\n",
    "y = data['price']\n",
    "\n",
    "# Spliting data to training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary contains all models we want to create\n",
    "models = {\n",
    "        'linear': {'model': LinearRegression()},\n",
    "        'ridge1': {'model': Ridge(), 'degree' : 1},\n",
    "        'lasso1': {'model': Lasso(), 'degree' : 1},\n",
    "        'ploy_2': {'model': LinearRegression(), 'degree' : 2},\n",
    "        'ridge2': {'model': Ridge(), 'degree' : 2},\n",
    "        'lasso2': {'model': Lasso(), 'degree' : 2},\n",
    "        'ridge3': {'model': Ridge(), 'degree' : 3},\n",
    "        'lasso3': {'model': Lasso(), 'degree' : 3},\n",
    "        'ploy_3': {'model': LinearRegression(), 'degree' : 3},\n",
    "        'knn'   : {'model': KNeighborsRegressor(n_neighbors=3)},\n",
    "        'D_tree': {'model': DecisionTreeRegressor(random_state=0)}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained ->  {'model': LinearRegression()}\n",
      "Trained ->  {'model': Ridge(), 'degree': 1}\n",
      "Trained ->  {'model': Lasso(), 'degree': 1}\n",
      "Trained ->  {'model': LinearRegression(), 'degree': 2}\n",
      "Trained ->  {'model': Ridge(), 'degree': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Documents\\capo\\ML\\Take session\\project phase 1\\Predict-Car-Price-\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.761e+11, tolerance: 5.792e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained ->  {'model': Lasso(), 'degree': 2}\n",
      "Trained ->  {'model': Ridge(), 'degree': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Documents\\capo\\ML\\Take session\\project phase 1\\Predict-Car-Price-\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 5.792e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained ->  {'model': Lasso(), 'degree': 3}\n",
      "Trained ->  {'model': LinearRegression(), 'degree': 3}\n",
      "Trained ->  {'model': KNeighborsRegressor(n_neighbors=3)}\n",
      "Trained ->  {'model': DecisionTreeRegressor(random_state=0)}\n"
     ]
    }
   ],
   "source": [
    "# Training models\n",
    "models = train_models(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation models on test dataset by score r^2 metric\n",
    "models = evaluation_models(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation models on train dataset by score r^2 metric\n",
    "models = evaluation_models(models, X_train, y_train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score for  linear  :  58.033892705985465\n",
      "Test Score for  linear  :  52.19344833114866\n",
      "\n",
      "Train Score for  ridge1  :  57.63069237170526\n",
      "Test Score for  ridge1  :  51.7137641210706\n",
      "\n",
      "Train Score for  lasso1  :  57.95717858936595\n",
      "Test Score for  lasso1  :  52.11878098028333\n",
      "\n",
      "Train Score for  ploy_2  :  83.95027175120154\n",
      "Test Score for  ploy_2  :  -0.05630833328733598\n",
      "\n",
      "Train Score for  ridge2  :  81.0858664798923\n",
      "Test Score for  ridge2  :  59.58241025058977\n",
      "\n",
      "Train Score for  lasso2  :  81.86919348748094\n",
      "Test Score for  lasso2  :  57.337443774084996\n",
      "\n",
      "Train Score for  ridge3  :  94.46404420266309\n",
      "Test Score for  ridge3  :  0.412887677129703\n",
      "\n",
      "Train Score for  lasso3  :  94.40237317459082\n",
      "Test Score for  lasso3  :  34.459363281033006\n",
      "\n",
      "Train Score for  ploy_3  :  97.41109163977613\n",
      "Test Score for  ploy_3  :  -0.08998636839514518\n",
      "\n",
      "Train Score for  knn  :  72.53226352356124\n",
      "Test Score for  knn  :  38.157019444321726\n",
      "\n",
      "Train Score for  D_tree  :  99.99813098066798\n",
      "Test Score for  D_tree  :  57.78751643144253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display score value on the test dataset for each model \n",
    "for model in models.keys():\n",
    "    print('Train Score for ', model,' : ', models[model]['Train_Score']*100)\n",
    "    print('Test Score for ', model,' : ', models[model]['Test_Score']*100, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle best model to use it\n",
    "pickle.dump(models['ridge2']['model'], open('../pkls/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metadata = {}\n",
    "\n",
    "models_metadata = models\n",
    "\n",
    "models_metadata['Test Size'] = 0.3\n",
    "models_metadata['Metric Evaluation'] = 'r^2 score'\n",
    "models_metadata['Data Shape Used'] = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../metadata/models_metadata.txt\", 'w') as f: \n",
    "    for key, value in models_metadata.items(): \n",
    "        f.write('%s:%s\\n' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle polynomial model to use it\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "poly.fit(X_train)\n",
    "pickle.dump(poly, open('../pkls/polynomial_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cbf47e6c8d049eb155badf242ecb35eb8e14463d1ece3cbc8a78e7719f8e5ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
